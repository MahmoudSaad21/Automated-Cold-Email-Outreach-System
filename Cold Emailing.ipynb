{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  **Cold emailing**\n",
        "\n",
        "### **Introduction**\n",
        "\n",
        "This code implements an **Automated Cold Emailing System** designed for businesses to streamline their outreach process using AI-driven content generation and efficient email management workflows. The system integrates various components to handle the complete email lifecycle, from crafting personalized messages to managing responses and logging communication for future reference.\n",
        "\n",
        "### **Key Features:**\n",
        "1. **Automated Email Generation & Sending:**\n",
        "   - Leverages **Meta LLaMA-3.2-3B-Instruct** for generating customized email content tailored to specific company needs.\n",
        "   - Extracts relevant product information from a **PDF catalog** to enhance email personalization using **Retrieval-Augmented Generation (RAG)**.\n",
        "   - Sends emails via **SMTP (Gmail)** with attachments and stores sent emails in an **SQLite database** for easy tracking.\n",
        "\n",
        "2. **Response Management & Classification:**\n",
        "   - Periodically checks for incoming responses using **IMAP**, categorizing replies as:\n",
        "     - **Not Interested** (ignored)\n",
        "     - **Need More Details** (handled by querying the AI with product data)\n",
        "     - **Meeting Request** (forwarded to HR automatically)\n",
        "   - Uses **Qwen 2.5 model** with **4-bit quantization** for accurate response classification.\n",
        "\n",
        "3. **Product Recommendation System:**\n",
        "   - Utilizes **FAISS (Facebook AI Similarity Search)** and **Sentence Transformers** for efficient retrieval of relevant product suggestions based on customer needs.\n",
        "   - Embeds product descriptions to find the most relevant offerings in real time.\n",
        "\n",
        "4. **Database & Event-Driven Architecture:**\n",
        "   - **SQLite database** manages email logs (sent/received) with timestamp tracking.\n",
        "   - Event-driven logic ensures that responses are processed automatically without manual intervention.\n",
        "\n",
        "5. **Technologies & Libraries Used:**\n",
        "   - **Python Libraries:** `pandas`, `transformers`, `smtplib`, `PyPDF2`, `faiss`, `sqlite3`, `sentence-transformers`\n",
        "   - **AI Models:** Meta LLaMA, Qwen 2.5 for classification\n",
        "   - **Email Protocols:** SMTP (sending) & IMAP (receiving)\n",
        "   - **Database:** SQLite for email logging and tracking\n",
        "\n",
        "### **Usage Workflow:**\n",
        "1. Reads company information from a CSV file and product details from a PDF catalog.\n",
        "2. Generates personalized emails using AI, attaches relevant product details, and sends them via Gmail SMTP.\n",
        "3. Stores all sent and received emails in an SQLite database for future reference.\n",
        "4. Continuously monitors email responses, classifies them, and triggers the next action accordingly.\n"
      ],
      "metadata": {
        "id": "HpR-BA8-EGDG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ba99c5a"
      },
      "source": [
        "# installs the necessary Python libraries\n",
        "This cell installs the necessary Python libraries required for the cold emailing automation system. These packages include:\n",
        "\n",
        "* pandas: For data manipulation and analysis, especially with CSV files.\n",
        "\n",
        "* transformers: To work with pre-trained language models for generating email content.\n",
        "\n",
        "* smtplib: To send emails using the Simple Mail Transfer Protocol (SMTP).\n",
        "\n",
        "* PyPDF2: For extracting product information from PDF documents.\n",
        "\n",
        "* bitsandbytes: Optimizes model loading and quantization for efficient processing.\n",
        "\n",
        "* faiss-cpu: A library for efficient similarity search, useful for finding relevant products based on company needs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFBkFBsTqIH2",
        "outputId": "d59bfcae-2388-4fe8-c181-581e8041768a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement smtplib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for smtplib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 bitsandbytes-0.45.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas transformers smtplib\n",
        "!pip install PyPDF2 bitsandbytes\n",
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8af05ff"
      },
      "source": [
        "# logs into Hugging Face\n",
        "This cell logs into Hugging Face to authenticate and access pre-trained models from the Hugging Face Model Hub. This step is essential for generating high-quality email content using advanced language models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkd8YlJ4eF0E",
        "outputId": "fc73a0b4-97f9-43ea-95ee-2ae42f1b0e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Cosmos` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Cosmos`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f110b7c"
      },
      "source": [
        "# script to sent first time\n",
        "This cell initializes the core functionalities of the cold emailing system, including:\n",
        "\n",
        "* Library Imports: Imports necessary modules for email handling, database management, NLP, and PDF processing.\n",
        "\n",
        "* SMTP Configuration: Configures the Gmail SMTP server to send emails securely.\n",
        "\n",
        "* Credentials Setup: Uses Gmail credentials (with an app password) for authentication.\n",
        "\n",
        "* Data Handling: Reads company details from a CSV file and extracts product information from a PDF catalog.\n",
        "\n",
        "* Database Initialization: Sets up an SQLite database to log sent and received emails.\n",
        "\n",
        "* Product Extraction: Extracts and organizes product details from the PDF.\n",
        "\n",
        "* Embedding & Similarity Search: Creates FAISS indexes to find relevant products based on company needs.\n",
        "\n",
        "* Email Generation: Uses an LLM to craft personalized emails with compelling subjects and content.\n",
        "\n",
        "* Email Sending: Sends customized emails to all companies listed in the CSV and logs them in the database.\n",
        "\n",
        "* Database Interaction: Includes functions to log, retrieve, and categorize emails for efficient tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldN2ehtn80R9",
        "outputId": "887dc286-cc3e-4198-a826-d2f45f4a253f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing first_sent.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile first_sent.py\n",
        "import time\n",
        "import random\n",
        "import smtplib\n",
        "import os\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import torch\n",
        "from email import encoders\n",
        "from email.mime.base import MIMEBase\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import re\n",
        "import sqlite3\n",
        "\n",
        "# Gmail SMTP Configuration\n",
        "SMTP_SERVER = \"smtp.gmail.com\"\n",
        "SMTP_PORT = 465\n",
        "\n",
        "# Your Gmail Credentials (Use App Password, NOT Gmail password)\n",
        "sender_email = \"your_email\"\n",
        "app_password = \"your_gmail_password\"\n",
        "\n",
        "# File paths\n",
        "csv_file = \"VR_and_Software_Companies_2.csv\"\n",
        "pdf_file = \"detailed_product_catalog.pdf\"\n",
        "\n",
        "model = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "\n",
        "sender_name = \"Mahmoud Saad\"\n",
        "sender_company = \"Freelance\"\n",
        "\n",
        "# Read CSV containing company details\n",
        "companies_df = pd.read_csv(csv_file)\n",
        "\n",
        "# Connect to SQLite database (or create it if it doesn't exist)\n",
        "conn = sqlite3.connect('emails.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create a table to store emails\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS emails (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    company_name TEXT NOT NULL,\n",
        "    email TEXT NOT NULL,\n",
        "    subject TEXT NOT NULL,\n",
        "    message TEXT NOT NULL,\n",
        "    category TEXT NOT NULL,  -- 'sent' or 'received'\n",
        "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "''')\n",
        "\n",
        "conn.commit()\n",
        "\n",
        "def extract_subject_and_body(conversation):\n",
        "    # Find the assistant's response\n",
        "    assistant_response = next((item for item in conversation if item.get('role') == 'assistant'), None)\n",
        "\n",
        "    if assistant_response:\n",
        "        response_text = assistant_response.get('content', '')\n",
        "    else:\n",
        "        return \"No Subject\", \"No Content\"\n",
        "\n",
        "    # Extract subject\n",
        "    subject_match = re.search(r\"Subject:\\s*(.*)\", response_text, re.IGNORECASE)\n",
        "    subject = subject_match.group(1).strip() if subject_match else \"No Subject\"\n",
        "\n",
        "    # Extract body: captures everything after the first \"Subject\" line\n",
        "    body_match = re.search(r\"Subject:.*?\\n+(.*)\", response_text, re.DOTALL)\n",
        "    email_body = body_match.group(1).strip() if body_match else response_text.strip()\n",
        "\n",
        "    return subject, email_body\n",
        "\n",
        "# Extract product information from PDF\n",
        "def extract_products_from_pdf(pdf_path):\n",
        "    products = []\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "        lines = text.split(\"\\n\")\n",
        "        for i in range(len(lines)):\n",
        "            if \"Product:\" in lines[i]:\n",
        "                product_name = lines[i].replace(\"Product: \", \"\").strip()\n",
        "                industry = lines[i + 1].replace(\"Industry: \", \"\").strip()\n",
        "                description = lines[i + 2].replace(\"Description: \", \"\").strip()\n",
        "                specifications = lines[i + 3].replace(\"Specifications: \", \"\").strip()\n",
        "                case_study = lines[i + 4].replace(\"Case Study: \", \"\").strip()\n",
        "                compliance = lines[i + 5].replace(\"Compliance: \", \"\").strip()\n",
        "                products.append({\n",
        "                    \"Product Name\": product_name,\n",
        "                    \"Industry\": industry,\n",
        "                    \"Description\": description,\n",
        "                    \"Specifications\": specifications,\n",
        "                    \"Case Study\": case_study,\n",
        "                    \"Compliance\": compliance\n",
        "                })\n",
        "    return products\n",
        "\n",
        "product_list = extract_products_from_pdf(pdf_file)\n",
        "\n",
        "# Load Sentence Transformer model for embeddings\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Create FAISS index for product descriptions\n",
        "def create_faiss_index(products):\n",
        "    descriptions = [p['Description'] for p in products]\n",
        "    embeddings = embedder.encode(descriptions)\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(np.array(embeddings))\n",
        "    return index, descriptions\n",
        "\n",
        "faiss_index, product_descriptions = create_faiss_index(product_list)\n",
        "\n",
        "# Function to find relevant products using embeddings\n",
        "def find_relevant_products(need, top_k=3):\n",
        "    need_embedding = embedder.encode([need])\n",
        "    distances, indices = faiss_index.search(np.array(need_embedding), top_k)\n",
        "    return [product_list[i] for i in indices[0]]\n",
        "\n",
        "# Function to generate customized email and subject using LLM\n",
        "def generate_email_and_subject(company_name, industry, need):\n",
        "    relevant_products = find_relevant_products(need)\n",
        "    product_suggestions = \"\\n\".join([f\"- {p['Product Name']}: {p['Description']}\" for p in relevant_products])\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional email assistant specializing in crafting compelling and structured business emails.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Generate a professional email with a compelling subject for {company_name} team in a company in {company_name}, a company in the {industry} industry.\\n\\nThe company has expressed a need for {need}, and we offer the following relevant products:\\n\\n{product_suggestions}\\n\\nThe email should include:\\n- A relevant subject line\\n- A personalized greeting\\n- A concise, engaging introduction\\n- A brief mention of the relevant products\\n- A clear call to action for scheduling a discussion or demo\\n- A professional closing with the sender's name ({sender_name}) and company ({sender_company})\\n\\nRespond with only the email subject and body.\"}\n",
        "    ]\n",
        "\n",
        "    output = model(messages, max_new_tokens=512)[0]['generated_text']\n",
        "    print(output)\n",
        "    subject, email_body = extract_subject_and_body(output)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print(subject)\n",
        "    return subject, email_body\n",
        "\n",
        "# Function to send email and log it\n",
        "def send_email(to_email, company_name, industry, need):\n",
        "    try:\n",
        "        subject, email_body = generate_email_and_subject(company_name, industry, need)\n",
        "\n",
        "        message = MIMEMultipart()\n",
        "        message[\"From\"] = sender_email\n",
        "        message[\"To\"] = to_email\n",
        "        message[\"Subject\"] = subject\n",
        "        message.attach(MIMEText(email_body, \"plain\"))\n",
        "\n",
        "        with open(pdf_file, \"rb\") as attachment:\n",
        "            part = MIMEBase(\"application\", \"octet-stream\")\n",
        "            part.set_payload(attachment.read())\n",
        "        encoders.encode_base64(part)\n",
        "        part.add_header(\"Content-Disposition\", f\"attachment; filename={os.path.basename(pdf_file)}\")\n",
        "        message.attach(part)\n",
        "\n",
        "        with smtplib.SMTP_SSL(SMTP_SERVER, SMTP_PORT) as server:\n",
        "            server.login(sender_email, app_password)\n",
        "            server.sendmail(sender_email, to_email, message.as_string())\n",
        "\n",
        "        # Log the sent email in the SQLite database\n",
        "        cursor.execute('''\n",
        "        INSERT INTO emails (company_name, email, subject, message, category)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        ''', (company_name, to_email, subject, email_body, 'sent'))\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error sending email to {company_name} ({to_email}): {e}\")\n",
        "\n",
        "# Function to store received emails\n",
        "def store_received_email(company_name, email, subject, message):\n",
        "    cursor.execute('''\n",
        "    INSERT INTO emails (company_name, email, subject, message, category)\n",
        "    VALUES (?, ?, ?, ?, ?)\n",
        "    ''', (company_name, email, subject, message, 'received'))\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "# Function to retrieve emails\n",
        "def get_emails(category=None):\n",
        "    if category:\n",
        "        cursor.execute('SELECT * FROM emails WHERE category = ?', (category,))\n",
        "    else:\n",
        "        cursor.execute('SELECT * FROM emails')\n",
        "\n",
        "    return cursor.fetchall()\n",
        "\n",
        "# Send emails to all companies\n",
        "for _, row in companies_df.iterrows():\n",
        "    send_email(row[\"Email\"], row[\"Company Name\"], row[\"Industry\"], row[\"Need\"])\n",
        "\n",
        "# Example usage:\n",
        "sent_emails = get_emails(category='sent')\n",
        "received_emails = get_emails(category='received')\n",
        "\n",
        "print(\"Sent Emails:\")\n",
        "for email in sent_emails:\n",
        "    print(email)\n",
        "\n",
        "print(\"\\nReceived Emails:\")\n",
        "for email in received_emails:\n",
        "    print(email)\n",
        "\n",
        "# Close the database connection\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "affedaf0"
      },
      "source": [
        "\n",
        "# ğŸ“§ **Script 1: `event_driven_emails.py`**  \n",
        "**Purpose:**  \n",
        "This script continuously monitors your Gmail inbox for unread emails. It handles the queuing and processing of these emails using an SQLite database and external scripts.  \n",
        "\n",
        "#### ğŸ—‚ï¸ **Key Components:**  \n",
        "1. **Imports & Setup:**  \n",
        "   - Libraries like `imaplib`, `email`, `sqlite3`, `subprocess`, and `psutil` are used for email handling, database interaction, and process management.  \n",
        "   - Email credentials and paths for the database, queue, and process scripts are defined.  \n",
        "\n",
        "2. **Database Initialization:**  \n",
        "   - Creates an `emails` table in SQLite if it doesn't exist to store email metadata (company, subject, message, etc.).  \n",
        "\n",
        "3. **Email Monitoring Functions:**  \n",
        "   - **`fetch_unread_emails()`**: Connects to Gmail, fetches unread emails, extracts relevant information (sender, subject, body), and stores them in the database if the sender exists.  \n",
        "   - **`mark_email_as_read()`**: Marks processed emails as read.  \n",
        "\n",
        "4. **Queue Handling:**  \n",
        "   - **`add_to_queue()`**: Adds new emails to a JSON-based queue if the processing script is busy.  \n",
        "   - **`process_queue()`**: Processes queued emails once the system is free.  \n",
        "\n",
        "5. **Integration with External Script:**  \n",
        "   - **`send_emails_to_script()`**: Forwards emails to `response.py` for classification and response generation.  \n",
        "\n",
        "6. **Continuous Loop:**  \n",
        "   - Runs every 60 seconds to check for new emails, manage the queue, and trigger processing tasks.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ23W-nLF-mN",
        "outputId": "4acc2178-dcb1-414a-bcd2-337ae7cc03e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing event_driven_emails.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile event_driven_emails.py\n",
        "import imaplib\n",
        "import email\n",
        "import time\n",
        "import sqlite3\n",
        "import subprocess\n",
        "import json\n",
        "from email.header import decode_header\n",
        "import psutil  # To check if the external script is running\n",
        "import time\n",
        "import random\n",
        "import smtplib\n",
        "import os\n",
        "import sqlite3\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import faiss\n",
        "import re\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "\n",
        "\n",
        "# Email credentials\n",
        "EMAIL_USER = \"your_email\"\n",
        "EMAIL_PASSWORD = \"your_gmail_password\"  # Use an app password if required\n",
        "IMAP_SERVER = \"imap.gmail.com\"\n",
        "\n",
        "# SQLite database path\n",
        "SQLITE_DB = \"emails.db\"\n",
        "TEMP_FILE = \"temp_emails.json\"  # Temporary file for email list\n",
        "QUEUE_FILE = \"email_queue.json\"   # âœ… Queue file for pending emails\n",
        "PROCESS_SCRIPT = \"response.py\"  # External script to handle emails\n",
        "\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect(SQLITE_DB)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create emails table if it doesn't exist\n",
        "cursor.execute('''\n",
        "CREATE TABLE IF NOT EXISTS emails (\n",
        "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    company_name TEXT NOT NULL,\n",
        "    email TEXT NOT NULL,\n",
        "    subject TEXT NOT NULL,\n",
        "    message TEXT NOT NULL,\n",
        "    category TEXT NOT NULL,  -- 'sent' or 'received'\n",
        "    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
        ")\n",
        "''')\n",
        "conn.commit()\n",
        "\n",
        "# âœ… Check if the response.py script is running\n",
        "def is_process_running(script_name):\n",
        "    for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "        if script_name in proc.info['cmdline']:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "# âœ… Add emails to the queue\n",
        "def add_to_queue(email_list):\n",
        "    with open(QUEUE_FILE, \"r\") as file:\n",
        "        queue = json.load(file)\n",
        "\n",
        "    queue.extend(email_list)\n",
        "\n",
        "    with open(QUEUE_FILE, \"w\") as file:\n",
        "        json.dump(queue, file)\n",
        "\n",
        "    print(f\"Queued {len(email_list)} emails.\")\n",
        "\n",
        "# âœ… Process emails from the queue\n",
        "def process_queue():\n",
        "    with open(QUEUE_FILE, \"r\") as file:\n",
        "        queued_emails = json.load(file)\n",
        "\n",
        "    if queued_emails:\n",
        "        print(f\"Processing {len(queued_emails)} queued emails...\")\n",
        "        send_emails_to_script(queued_emails)\n",
        "\n",
        "        # Clear the queue after processing\n",
        "        with open(QUEUE_FILE, \"w\") as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "\n",
        "def mark_email_as_read(mail, email_id):\n",
        "    \"\"\"Mark the email as read.\"\"\"\n",
        "    mail.store(email_id, '+FLAGS', '\\\\Seen')\n",
        "\n",
        "def fetch_unread_emails():\n",
        "    \"\"\"Fetch unread emails from the inbox.\"\"\"\n",
        "    try:\n",
        "        mail = imaplib.IMAP4_SSL(IMAP_SERVER)\n",
        "        mail.login(EMAIL_USER, EMAIL_PASSWORD)\n",
        "        mail.select(\"inbox\")  # Select inbox\n",
        "\n",
        "        # Search for unread emails\n",
        "        status, messages = mail.search(None, \"UNSEEN\")\n",
        "        email_ids = messages[0].split()\n",
        "\n",
        "        if not email_ids:\n",
        "            print(\"No new emails found.\")\n",
        "            mail.logout()\n",
        "            return []\n",
        "\n",
        "        EMAIL_LIST = []  # Store extracted email addresses\n",
        "        for num in reversed(email_ids):  # Process from latest to oldest\n",
        "            status, data = mail.fetch(num, \"(RFC822)\")\n",
        "            for response_part in data:\n",
        "                if isinstance(response_part, tuple):\n",
        "                    msg = email.message_from_bytes(response_part[1])\n",
        "\n",
        "                    # Decode email subject\n",
        "                    subject, encoding = decode_header(msg[\"Subject\"])[0]\n",
        "                    if isinstance(subject, bytes):\n",
        "                        subject = subject.decode(encoding if encoding else 'utf-8')\n",
        "\n",
        "                    # Get sender email\n",
        "                    from_email = msg.get(\"From\")\n",
        "                    from_email = from_email.split(\"<\")[-1].strip(\">\")  # Extract clean email\n",
        "                    EMAIL_LIST.append(from_email)\n",
        "\n",
        "                    # Get email body\n",
        "                    body = \"\"\n",
        "                    for part in msg.walk():\n",
        "                        content_type = part.get_content_type()\n",
        "                        content_disposition = str(part.get(\"Content-Disposition\") or \"\")\n",
        "\n",
        "                        if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
        "                            body = part.get_payload(decode=True).decode(errors=\"ignore\")\n",
        "                            break  # Stop after getting the plain text part\n",
        "\n",
        "                    if not body:\n",
        "                        continue  # Skip if no body found\n",
        "                    print(f\"\\nNew Email from {from_email}: {subject}\")\n",
        "\n",
        "                    # âœ… Check if the sender exists in the contacts table\n",
        "                    cursor.execute('SELECT * FROM emails WHERE email = ?', (from_email,))\n",
        "                    contact = cursor.fetchone()\n",
        "\n",
        "                    if contact:  # âœ… Insert only if the sender exists in the database\n",
        "                        company_name = contact[1] if len(contact) > 1 else \"Unknown Company\"\n",
        "\n",
        "                        # âœ… Insert the received email into the SQLite database\n",
        "                        cursor.execute('''\n",
        "                            INSERT INTO emails (company_name, email, subject, message, category)\n",
        "                            VALUES (?, ?, ?, ?, ?)\n",
        "                        ''', (company_name, from_email, subject, body, 'received'))\n",
        "                        conn.commit()\n",
        "\n",
        "                        # âœ… Mark email as read only for known senders\n",
        "                        mark_email_as_read(mail, num)\n",
        "                    else:\n",
        "                        print(f\"Skipped email from unknown sender: {from_email}\")\n",
        "\n",
        "        mail.logout()\n",
        "        return EMAIL_LIST  # Return the list of emails\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", e)\n",
        "        return []\n",
        "\n",
        "def send_emails_to_script(email_list):\n",
        "    \"\"\"Pass the list of emails to another script (process_emails.py).\"\"\"\n",
        "    if email_list:\n",
        "        print(f\"Passing {len(email_list)} emails to {PROCESS_SCRIPT}...\")\n",
        "\n",
        "        # Save email list to a temporary file\n",
        "        with open(TEMP_FILE, \"w\") as file:\n",
        "            json.dump(email_list, file)\n",
        "\n",
        "        # Run the external script with the file path as an argument\n",
        "        subprocess.Popen([\"python\", PROCESS_SCRIPT, TEMP_FILE])\n",
        "\n",
        "# Ensure the queue file exists\n",
        "if not os.path.exists(QUEUE_FILE):\n",
        "    with open(QUEUE_FILE, \"w\") as file:\n",
        "        json.dump([], file)  # Initialize with an empty list\n",
        "\n",
        "\n",
        "# Run the script continuously every 60 seconds\n",
        "while True:\n",
        "    emails = fetch_unread_emails()\n",
        "\n",
        "    # Check the size of the email queue\n",
        "    with open(QUEUE_FILE, \"r\") as file:\n",
        "        queue_size = len(json.load(file))\n",
        "\n",
        "    if emails or queue_size != 0:\n",
        "        if is_process_running(PROCESS_SCRIPT):\n",
        "            # Add new emails to the queue if the process is running\n",
        "            add_to_queue(emails)\n",
        "        elif emails and queue_size != 0:\n",
        "            # Process queued emails first, then send new emails\n",
        "            process_queue()\n",
        "            send_emails_to_script(emails)\n",
        "        elif emails:\n",
        "            # Send new emails directly if there's no queue\n",
        "            send_emails_to_script(emails)\n",
        "        elif queue_size != 0:\n",
        "            # Process queued emails if no new emails are found\n",
        "            process_queue()\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6be25dc1"
      },
      "source": [
        "# ğŸ¤– **Script 2: `response.py`**  \n",
        "**Purpose:**  \n",
        "This script processes the emails passed from `event_driven_emails.py`. It classifies responses using a zero-shot classification model and generates replies when needed.  \n",
        "\n",
        "#### ğŸ—‚ï¸ **Key Components:**  \n",
        "1. **Imports & Setup:**  \n",
        "   - Uses libraries like `transformers`, `sqlite3`, `faiss`, and `PyPDF2` for NLP tasks, database access, and working with product catalogs.  \n",
        "   - Connects to the same SQLite database and loads the pending emails from a temporary JSON file.  \n",
        "\n",
        "2. **Model Initialization:**  \n",
        "   - **Zero-Shot Classification:** Uses Facebook's `BART-large-mnli` to classify email responses into categories:  \n",
        "     - **\"Not interested\"**  \n",
        "     - **\"Need more details\"**  \n",
        "     - **\"Want to make a meeting\"**  \n",
        "   - **LLM for Response Generation:** Uses Metaâ€™s LLaMA model to generate detailed responses when needed.  \n",
        "\n",
        "3. **Email Classification & Response:**  \n",
        "   - **`classify_email()`**: Determines the intent of the latest email response.  \n",
        "   - **`get_latest_response()` & `get_full_conversation()`**: Retrieve conversation history from the database to maintain context in replies.  \n",
        "   - **`extract_subject_and_body()`**: Parses the generated response to extract the subject and body for the reply.  \n",
        "\n",
        "4. **Sending Replies:**  \n",
        "   - Composes and sends emails when the classification result is **\"Need more details\"**.  \n",
        "   - For **\"Want to make a meeting\"**, it forwards the request to HR.  \n",
        "   - **\"Not interested\"** responses are ignored.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”„ **How They Work Together:**  \n",
        "1. **Email Received â†’** `event_driven_emails.py` detects it.  \n",
        "2. **Processing â†’** If busy, the email is queued; otherwise, it's sent to `response.py`.  \n",
        "3. **Classification â†’** `response.py` determines the email type.  \n",
        "4. **Action â†’** Sends an automated reply, forwards to HR, or ignores based on the classification.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCs66HGTNko8",
        "outputId": "2eb0453e-5a33-47b6-9026-0e62a7cab2ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing response.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile response.py\n",
        "import smtplib\n",
        "import os\n",
        "import json\n",
        "import sqlite3\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import faiss\n",
        "import re\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import psutil  # To check if the external script is running\n",
        "import time\n",
        "import random\n",
        "# File paths and email details\n",
        "SQLITE_DB = \"emails.db\"\n",
        "pdf_file = \"detailed_product_catalog.pdf\"\n",
        "json_file = \"temp_emails.json\"\n",
        "sender_email = \"your_email\"\n",
        "app_password = \"your_gmail_password\"\n",
        "sender_name = \"Mahmoud Saad\"\n",
        "sender_company = \"Freelance\"\n",
        "\n",
        "# Load email list from JSON file\n",
        "with open(json_file, \"r\") as file:\n",
        "    email_list = json.load(file)\n",
        "print(email_list)\n",
        "# Connect to SQLite database\n",
        "conn = sqlite3.connect(SQLITE_DB)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Load BART MNLI zero-shot classification pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "\n",
        "# Load Llama model\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "# Classification categories\n",
        "categories = [\"Not interested\", \"Need more details\", \"Want to make a meeting\"]\n",
        "\n",
        "def classify_email(response):\n",
        "    if not response or response.lower() == \"no response\":\n",
        "        return \"No Response\"\n",
        "    result = classifier(response, candidate_labels=categories)\n",
        "    return result['labels'][0]\n",
        "\n",
        "def get_latest_response(email):\n",
        "    \"\"\"Retrieve the latest response for a given email.\"\"\"\n",
        "    cursor.execute('''\n",
        "    SELECT message FROM emails\n",
        "    WHERE email = ? AND category = 'received'\n",
        "    ORDER BY timestamp DESC\n",
        "    LIMIT 1\n",
        "    ''', (email,))\n",
        "    result = cursor.fetchone()\n",
        "    return result[0] if result else None\n",
        "\n",
        "def get_full_conversation(email):\n",
        "    \"\"\"Retrieve the full conversation history for a given email.\"\"\"\n",
        "    cursor.execute('''\n",
        "    SELECT message, category FROM emails\n",
        "    WHERE email = ?\n",
        "    ORDER BY timestamp ASC\n",
        "    ''', (email,))\n",
        "    results = cursor.fetchall()\n",
        "    conversation = []\n",
        "    for message, category in results:\n",
        "        conversation.append(f\"{category}: {message}\")\n",
        "    return \"\\n\".join(conversation)\n",
        "\n",
        "def extract_subject_and_body(conversation):\n",
        "    # Find the assistant's response\n",
        "    assistant_response = next((item for item in conversation if item.get('role') == 'assistant'), None)\n",
        "\n",
        "    if assistant_response:\n",
        "        response_text = assistant_response.get('content', '')\n",
        "    else:\n",
        "        return \"No Subject\", \"No Content\"\n",
        "\n",
        "    # Extract subject\n",
        "    subject_match = re.search(r\"Subject:\\s*(.*)\", response_text, re.IGNORECASE)\n",
        "    subject = subject_match.group(1).strip() if subject_match else \"No Subject\"\n",
        "\n",
        "    # Extract body: captures everything after the first \"Subject\" line\n",
        "    body_match = re.search(r\"Subject:.*?\\n+(.*)\", response_text, re.DOTALL)\n",
        "    email_body = body_match.group(1).strip() if body_match else response_text.strip()\n",
        "\n",
        "    return subject, email_body\n",
        "\n",
        "def extract_products_from_pdf(pdf_path):\n",
        "    products = []\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "        lines = text.split(\"\\n\")\n",
        "        for i in range(len(lines)):\n",
        "            if \"Product:\" in lines[i]:\n",
        "                product_name = lines[i].replace(\"Product: \", \"\").strip()\n",
        "                industry = lines[i + 1].replace(\"Industry: \", \"\").strip()\n",
        "                description = lines[i + 2].replace(\"Description: \", \"\").strip()\n",
        "                specifications = lines[i + 3].replace(\"Specifications: \", \"\").strip()\n",
        "                case_study = lines[i + 4].replace(\"Case Study: \", \"\").strip()\n",
        "                compliance = lines[i + 5].replace(\"Compliance: \", \"\").strip()\n",
        "                products.append({\n",
        "                    \"Product Name\": product_name,\n",
        "                    \"Industry\": industry,\n",
        "                    \"Description\": description,\n",
        "                    \"Specifications\": specifications,\n",
        "                    \"Case Study\": case_study,\n",
        "                    \"Compliance\": compliance\n",
        "                })\n",
        "    return products\n",
        "\n",
        "product_list = extract_products_from_pdf(pdf_file)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def create_embeddings(products):\n",
        "    product_embeddings = []\n",
        "    for product in products:\n",
        "        text = f\"Product: {product['Product Name']}, Description: {product['Description']}, Specifications: {product['Specifications']}, Case Study: {product['Case Study']}, Compliance: {product['Compliance']}\"\n",
        "        embedding = embedding_model.encode(text)\n",
        "        product_embeddings.append(embedding)\n",
        "    return np.array(product_embeddings)\n",
        "\n",
        "product_embeddings = create_embeddings(product_list)\n",
        "index = faiss.IndexFlatL2(product_embeddings.shape[1])\n",
        "index.add(product_embeddings)\n",
        "\n",
        "def get_relevant_product(query):\n",
        "    query_embedding = embedding_model.encode([query])\n",
        "    query_embedding = np.array(query_embedding)\n",
        "    _, indices = index.search(query_embedding, k=1)\n",
        "    return product_list[indices[0][0]]\n",
        "\n",
        "def generate_email_and_subject(company_name, industry, conversation):\n",
        "    relevant_product = get_relevant_product(conversation)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional email assistant who writes structured responses.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Given the conversation history for {company_name} in the {industry} industry, generate a well-structured response.\\n\\nConversation:\\n{conversation}\\n\\nProduct Details:\\n- {relevant_product}\"}\n",
        "    ]\n",
        "    outputs = pipe(messages, max_new_tokens=512)\n",
        "    response_text = outputs[0][\"generated_text\"]\n",
        "    subject, email_body = extract_subject_and_body(response_text)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return subject, email_body\n",
        "\n",
        "# Process each email in the list\n",
        "for email in email_list:\n",
        "    print(f\"Processing email from {email}...\")\n",
        "    latest_response = get_latest_response(email)\n",
        "    category = classify_email(latest_response)\n",
        "    print(f\"Category: {category}\")\n",
        "    if category == \"Need more details\":\n",
        "        conversation = get_full_conversation(email)\n",
        "        cursor.execute('''\n",
        "        SELECT company_name, subject FROM emails\n",
        "        WHERE email = ? AND category = 'received'\n",
        "        ORDER BY timestamp DESC\n",
        "        LIMIT 1\n",
        "        ''', (email,))\n",
        "        result = cursor.fetchone()\n",
        "        if result:\n",
        "            company_name, industry = result\n",
        "            subject, response = generate_email_and_subject(company_name, industry, conversation)\n",
        "\n",
        "            # Insert the sent email into the SQLite database\n",
        "            cursor.execute('''\n",
        "            INSERT INTO emails (company_name, email, subject, message, category)\n",
        "            VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (company_name, email, subject, response, 'sent'))\n",
        "            conn.commit()\n",
        "\n",
        "            # Send the email\n",
        "            message = MIMEMultipart()\n",
        "            message[\"From\"], message[\"To\"], message[\"Subject\"] = sender_email, email, subject\n",
        "            message.attach(MIMEText(response, \"plain\"))\n",
        "\n",
        "            with smtplib.SMTP_SSL(\"smtp.gmail.com\", 465) as server:\n",
        "                server.login(sender_email, app_password)\n",
        "                server.sendmail(sender_email, email, message.as_string())\n",
        "\n",
        "            print(f\"Sent response to {email} for {company_name}\")\n",
        "\n",
        "conn.close()\n",
        "print(\"âœ… Emails categorized, responses sent, and database updated.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bda98993"
      },
      "source": [
        "run the script"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python first_sent.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAzEpldqnt2y",
        "outputId": "386a8e07-3304-4c20-ff72-a10a66f7a7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-10 12:24:16.616537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739190256.925127     887 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739190257.011323     887 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-10 12:24:17.589945: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 878/878 [00:00<00:00, 6.39MB/s]\n",
            "model.safetensors.index.json: 100% 20.9k/20.9k [00:00<00:00, 72.3MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.97G [00:00<02:00, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.97G [00:00<01:57, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<01:55, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.97G [00:00<01:54, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.97G [00:01<01:55, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.97G [00:01<01:55, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:01<01:55, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.97G [00:01<01:54, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.97G [00:02<01:54, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.97G [00:02<01:54, 42.6MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.97G [00:02<01:54, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.97G [00:02<01:53, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.97G [00:03<01:53, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.97G [00:03<01:52, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.97G [00:03<01:52, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.97G [00:03<01:53, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.97G [00:04<01:53, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.97G [00:04<01:52, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.97G [00:04<01:51, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.97G [00:04<01:51, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.97G [00:05<01:51, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.97G [00:05<01:51, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.97G [00:05<01:50, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.97G [00:05<01:50, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.97G [00:06<01:50, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.97G [00:06<01:49, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.97G [00:06<01:49, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.97G [00:06<01:49, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.97G [00:07<01:48, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.97G [00:07<01:48, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.97G [00:07<01:48, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.97G [00:07<01:49, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.97G [00:08<01:48, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:08<01:48, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.97G [00:08<01:48, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:08<01:47, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.97G [00:09<01:46, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:09<01:46, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.97G [00:09<01:46, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:09<01:46, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.97G [00:10<01:46, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.97G [00:10<01:46, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.97G [00:10<01:45, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.97G [00:10<01:45, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 472M/4.97G [00:11<01:45, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:11<01:45, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.97G [00:11<01:44, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:11<01:44, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.97G [00:12<01:43, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:12<01:43, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.97G [00:12<01:43, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.97G [00:12<01:42, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.97G [00:13<01:42, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.97G [00:13<01:42, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.97G [00:13<01:42, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.97G [00:13<01:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.97G [00:14<01:42, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.97G [00:14<01:42, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.97G [00:14<01:41, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:14<01:42, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.97G [00:15<01:41, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:15<01:40, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.97G [00:15<01:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 671M/4.97G [00:15<01:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.97G [00:15<01:41, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:16<01:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.97G [00:16<01:58, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.97G [00:16<01:34, 44.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:17<01:35, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.97G [00:17<01:36, 43.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:17<01:36, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.97G [00:17<01:37, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:18<01:36, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.97G [00:18<01:36, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:18<01:36, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.97G [00:18<01:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:19<01:36, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.97G [00:19<01:35, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:19<01:36, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.97G [00:19<01:35, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:20<01:35, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 870M/4.97G [00:20<01:35, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:20<01:35, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.97G [00:20<01:35, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:21<01:35, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.97G [00:21<01:34, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:21<01:34, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.97G [00:21<01:34, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:22<01:33, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.97G [00:22<01:33, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:22<01:33, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.97G [00:22<01:33, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:23<01:32, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.97G [00:23<01:32, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:23<01:32, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.97G [00:23<01:32, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:24<01:32, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.97G [00:24<01:31, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:24<01:31, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.97G [00:24<01:30, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:25<01:31, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.97G [00:25<01:30, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:25<01:30, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.97G [00:25<01:30, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:26<01:29, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:26<01:29, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:26<01:29, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.97G [00:26<01:39, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.97G [00:26<01:25, 44.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.97G [00:27<01:26, 44.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:27<01:26, 43.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.97G [00:27<01:27, 43.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.97G [00:27<01:27, 43.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:28<01:27, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:28<01:28, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.97G [00:28<01:27, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:28<01:27, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.97G [00:29<01:26, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:29<01:29, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.27G/4.97G [00:29<01:27, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:29<01:27, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.97G [00:30<01:26, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:30<01:28, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.97G [00:30<01:26, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.97G [00:30<01:26, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.97G [00:31<01:25, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:31<01:28, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.97G [00:31<01:26, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:31<01:25, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.97G [00:32<01:24, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.97G [00:32<01:26, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:32<01:25, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.97G [00:32<01:24, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.42G/4.97G [00:33<01:24, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.97G [00:33<01:25, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:33<01:23, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.97G [00:33<01:23, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:34<01:22, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.47G/4.97G [00:34<01:24, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.97G [00:34<01:23, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.97G [00:34<01:22, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.97G [00:35<01:21, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:35<01:23, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:35<01:22, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.97G [00:35<01:21, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.97G [00:36<01:20, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:36<01:22, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.97G [00:36<01:21, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:37<01:32, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.97G [00:37<01:16, 44.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:37<01:19, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:37<01:18, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.61G/4.97G [00:37<01:18, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:38<01:18, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.97G [00:38<01:20, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:38<01:18, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.97G [00:38<01:17, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:39<01:17, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.97G [00:39<01:19, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.97G [00:39<01:17, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.97G [00:39<01:17, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.97G [00:40<01:16, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.97G [00:40<01:18, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.97G [00:40<01:17, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:40<01:16, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.97G [00:41<01:16, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.97G [00:41<01:17, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.97G [00:41<01:15, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.97G [00:41<01:15, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.97G [00:42<01:15, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.97G [00:42<01:16, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.81G/4.97G [00:42<01:15, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.97G [00:42<01:14, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:43<01:13, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.97G [00:43<01:15, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.97G [00:43<01:14, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.87G/4.97G [00:43<01:13, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:44<01:12, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/4.97G [00:44<01:14, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:44<01:13, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.97G [00:44<01:12, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:45<01:12, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.97G [00:45<01:13, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:45<01:12, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.97G [00:45<01:11, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:46<01:11, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.97G [00:46<01:12, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.97G [00:46<01:10, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.97G [00:46<01:10, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.97G [00:47<01:19, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.01G/4.97G [00:47<01:08, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:47<01:07, 43.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.97G [00:47<01:07, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:48<01:07, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.97G [00:48<01:09, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:48<01:08, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.97G [00:48<01:08, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.97G [00:49<01:07, 42.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.97G [00:49<01:09, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.97G [00:49<01:08, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:49<01:07, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.97G [00:50<01:06, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.97G [00:50<01:08, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:50<01:07, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.97G [00:50<01:06, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.97G [00:51<01:05, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.97G [00:51<01:07, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:51<01:06, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.97G [00:51<01:05, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.21G/4.97G [00:52<01:04, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.97G [00:52<01:06, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:52<01:05, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.97G [00:52<01:04, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:53<01:03, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.26G/4.97G [00:53<01:05, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.97G [00:53<01:04, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.97G [00:53<01:03, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.97G [00:54<01:02, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:54<01:04, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.97G [00:54<01:03, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.97G [00:54<01:02, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.97G [00:55<01:02, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.97G [00:55<01:03, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.36G/4.97G [00:55<01:02, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:55<01:01, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.97G [00:56<01:01, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.97G [00:56<01:02, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.97G [00:56<01:01, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.97G [00:56<01:00, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.97G [00:57<00:59, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.97G [00:57<01:06, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:57<00:58, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.97G [00:57<00:58, 42.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.97G [00:58<00:58, 42.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.97G [00:58<00:59, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [00:58<00:58, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.97G [00:58<00:58, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.97G [00:59<00:57, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.52G/4.97G [00:59<00:59, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.97G [00:59<00:58, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [00:59<00:57, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.97G [01:00<00:57, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.56G/4.97G [01:00<00:58, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [01:00<00:57, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.97G [01:00<00:56, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.97G [01:01<00:56, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.97G [01:01<00:56, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [01:01<00:56, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.97G [01:01<00:55, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.97G [01:02<00:54, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.97G [01:02<00:56, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.97G [01:02<00:55, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.97G [01:02<00:54, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.97G [01:03<00:54, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.97G [01:03<00:55, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.97G [01:03<00:54, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.97G [01:03<00:53, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.97G [01:04<00:52, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.97G [01:04<00:54, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.97G [01:04<00:53, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.97G [01:04<00:52, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.76G/4.97G [01:05<00:52, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.77G/4.97G [01:05<00:53, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [01:05<00:52, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.97G [01:05<00:51, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [01:06<00:51, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.97G [01:06<00:52, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.97G [01:06<00:51, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.97G [01:06<00:50, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.97G [01:07<00:50, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.97G [01:07<00:51, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.86G/4.97G [01:07<00:53, 39.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.97G [01:07<00:48, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.97G [01:08<00:48, 43.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.97G [01:08<00:49, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.97G [01:08<00:48, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.97G [01:08<00:48, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.97G [01:09<00:47, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.97G [01:09<00:49, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [01:09<00:48, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.96G/4.97G [01:09<00:47, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.97G [01:10<00:47, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [01:10<00:47, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.97G [01:10<00:47, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.97G [01:10<00:46, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.97G [01:11<00:46, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.97G [01:11<00:47, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.97G [01:11<00:46, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.97G [01:11<00:45, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.97G [01:12<00:45, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.06G/4.97G [01:12<00:46, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [01:12<00:45, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.97G [01:12<00:44, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.97G [01:13<00:44, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.10G/4.97G [01:13<00:45, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.11G/4.97G [01:13<00:44, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.97G [01:13<00:43, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.97G [01:14<00:43, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.97G [01:14<00:44, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.16G/4.97G [01:14<00:43, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.97G [01:14<00:42, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.97G [01:15<00:42, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.97G [01:15<00:42, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [01:15<00:42, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.21G/4.97G [01:15<00:41, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.97G [01:16<00:41, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [01:16<00:41, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.97G [01:16<00:40, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.97G [01:16<00:40, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.97G [01:17<00:40, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.97G [01:17<00:41, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.97G [01:17<00:40, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [01:18<00:41, 40.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.30G/4.97G [01:18<00:38, 43.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.97G [01:18<00:39, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.97G [01:18<00:38, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.97G [01:18<00:38, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.97G [01:19<00:38, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.36G/4.97G [01:19<00:38, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.97G [01:19<00:38, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.97G [01:19<00:37, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.97G [01:20<00:37, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.97G [01:20<00:38, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.41G/4.97G [01:20<00:37, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.97G [01:20<00:36, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.97G [01:21<00:36, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.97G [01:21<00:36, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [01:21<00:36, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.46G/4.97G [01:21<00:35, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.97G [01:22<00:35, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [01:22<00:35, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.97G [01:22<00:35, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.50G/4.97G [01:22<00:34, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.97G [01:23<00:34, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.97G [01:23<00:34, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.97G [01:23<00:34, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.97G [01:23<00:33, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.55G/4.97G [01:24<00:33, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.97G [01:24<00:33, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.97G [01:24<00:33, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.97G [01:24<00:32, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [01:25<00:32, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.61G/4.97G [01:25<00:32, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.97G [01:25<00:32, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.97G [01:25<00:31, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.97G [01:26<00:31, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.97G [01:26<00:31, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.66G/4.97G [01:26<00:31, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.97G [01:26<00:30, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.97G [01:27<00:30, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.97G [01:27<00:30, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.70G/4.97G [01:27<00:30, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.97G [01:27<00:29, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.97G [01:28<00:30, 40.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.97G [01:28<00:29, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.97G [01:28<00:28, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.75G/4.97G [01:28<00:28, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.76G/4.97G [01:29<00:28, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.97G [01:29<00:28, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.97G [01:29<00:28, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/4.97G [01:29<00:27, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [01:30<00:27, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.97G [01:30<00:27, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.97G [01:30<00:27, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.97G [01:30<00:26, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.97G [01:31<00:26, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.86G/4.97G [01:31<00:26, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.97G [01:31<00:26, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [01:31<00:25, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.97G [01:32<00:25, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.90G/4.97G [01:32<00:25, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [01:32<00:25, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.97G [01:32<00:24, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [01:33<00:24, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.97G [01:33<00:24, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.95G/4.97G [01:33<00:24, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.97G [01:33<00:23, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [01:34<00:23, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.97G [01:34<00:23, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.97G [01:34<00:23, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.01G/4.97G [01:34<00:22, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.97G [01:35<00:22, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.97G [01:35<00:22, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.97G [01:35<00:22, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.05G/4.97G [01:35<00:21, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.06G/4.97G [01:36<00:21, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.97G [01:36<00:21, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [01:36<00:21, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.97G [01:36<00:20, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.10G/4.97G [01:37<00:20, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.11G/4.97G [01:37<00:20, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.97G [01:37<00:20, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.97G [01:37<00:19, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.97G [01:38<00:19, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.97G [01:38<00:19, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.16G/4.97G [01:38<00:19, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.97G [01:38<00:18, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.97G [01:39<00:18, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/4.97G [01:39<00:18, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.20G/4.97G [01:39<00:18, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.97G [01:39<00:17, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.97G [01:40<00:17, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.97G [01:40<00:17, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.25G/4.97G [01:40<00:17, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.26G/4.97G [01:40<00:16, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.97G [01:41<00:16, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.97G [01:41<00:16, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.97G [01:41<00:16, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.30G/4.97G [01:41<00:15, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.97G [01:42<00:15, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.97G [01:42<00:15, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.97G [01:42<00:15, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.97G [01:42<00:14, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.97G [01:43<00:14, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.36G/4.97G [01:43<00:14, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.97G [01:43<00:14, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.97G [01:43<00:13, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/4.97G [01:44<00:13, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.40G/4.97G [01:44<00:13, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.97G [01:44<00:13, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/4.97G [01:44<00:12, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.97G [01:45<00:12, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.45G/4.97G [01:45<00:12, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.46G/4.97G [01:45<00:12, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.97G [01:45<00:11, 41.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.97G [01:46<00:11, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.97G [01:46<00:11, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.50G/4.97G [01:46<00:11, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [01:46<00:10, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.97G [01:47<00:10, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.97G [01:47<00:10, 41.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.97G [01:47<00:10, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.97G [01:47<00:09, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.97G [01:48<00:09, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.97G [01:48<00:09, 40.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [01:48<00:09, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.97G [01:48<00:08, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.60G/4.97G [01:49<00:08, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.97G [01:49<00:08, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.97G [01:49<00:08, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.97G [01:49<00:07, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.65G/4.97G [01:50<00:07, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.66G/4.97G [01:50<00:07, 41.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.97G [01:50<00:07, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.97G [01:50<00:06, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.97G [01:51<00:06, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.70G/4.97G [01:51<00:06, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.71G/4.97G [01:51<00:06, 41.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.97G [01:51<00:05, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.97G [01:52<00:05, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/4.97G [01:52<00:05, 41.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [01:52<00:05, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.97G [01:52<00:04, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.97G [01:53<00:04, 42.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.97G [01:53<00:04, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.97G [01:53<00:04, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.80G/4.97G [01:53<00:03, 42.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [01:54<00:03, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.97G [01:54<00:03, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.97G [01:54<00:03, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.84G/4.97G [01:54<00:02, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [01:55<00:02, 42.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.97G [01:55<00:02, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.97G [01:55<00:02, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.97G [01:55<00:01, 42.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.90G/4.97G [01:56<00:01, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.97G [01:56<00:01, 41.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.97G [01:56<00:01, 42.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.97G [01:56<00:00, 42.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.97G [01:57<00:00, 42.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.95G/4.97G [01:57<00:00, 41.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.96G/4.97G [01:57<00:00, 41.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [01:57<00:00, 42.1MB/s]\n",
            "Downloading shards:  50% 1/2 [01:58<01:58, 118.04s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.46G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/1.46G [00:00<00:33, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/1.46G [00:00<00:33, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 31.5M/1.46G [00:00<00:43, 32.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 52.4M/1.46G [00:01<00:30, 45.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 62.9M/1.46G [00:01<00:31, 44.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 73.4M/1.46G [00:01<00:31, 44.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 83.9M/1.46G [00:01<00:31, 43.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 94.4M/1.46G [00:02<00:31, 43.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 105M/1.46G [00:02<00:31, 42.9MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 115M/1.46G [00:02<00:31, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 126M/1.46G [00:02<00:31, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 136M/1.46G [00:03<00:30, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 147M/1.46G [00:03<00:30, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 157M/1.46G [00:03<00:30, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 168M/1.46G [00:03<00:30, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 178M/1.46G [00:04<00:29, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 189M/1.46G [00:04<00:29, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 199M/1.46G [00:04<00:29, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 210M/1.46G [00:04<00:29, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 220M/1.46G [00:05<00:28, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 231M/1.46G [00:05<00:28, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 241M/1.46G [00:05<00:28, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 252M/1.46G [00:05<00:28, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 262M/1.46G [00:06<00:27, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 273M/1.46G [00:06<00:27, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 283M/1.46G [00:06<00:27, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 294M/1.46G [00:06<00:27, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 304M/1.46G [00:07<00:27, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 315M/1.46G [00:07<00:26, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 325M/1.46G [00:07<00:26, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 336M/1.46G [00:07<00:26, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 346M/1.46G [00:08<00:26, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 357M/1.46G [00:08<00:25, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 367M/1.46G [00:08<00:25, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 377M/1.46G [00:08<00:25, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 388M/1.46G [00:09<00:24, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 398M/1.46G [00:09<00:24, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 409M/1.46G [00:09<00:24, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 419M/1.46G [00:09<00:24, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 430M/1.46G [00:10<00:23, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 440M/1.46G [00:10<00:23, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 451M/1.46G [00:10<00:23, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 461M/1.46G [00:10<00:23, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 472M/1.46G [00:11<00:23, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 482M/1.46G [00:11<00:22, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 493M/1.46G [00:11<00:22, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 503M/1.46G [00:11<00:22, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 514M/1.46G [00:12<00:22, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 524M/1.46G [00:12<00:21, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 535M/1.46G [00:12<00:21, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 545M/1.46G [00:12<00:21, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 556M/1.46G [00:12<00:21, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 566M/1.46G [00:13<00:20, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 577M/1.46G [00:13<00:20, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 587M/1.46G [00:13<00:20, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 598M/1.46G [00:13<00:20, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 608M/1.46G [00:14<00:19, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 619M/1.46G [00:14<00:19, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 629M/1.46G [00:14<00:24, 34.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 650M/1.46G [00:15<00:17, 45.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 661M/1.46G [00:15<00:17, 44.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 671M/1.46G [00:15<00:17, 44.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 682M/1.46G [00:15<00:17, 43.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 692M/1.46G [00:16<00:17, 43.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 703M/1.46G [00:16<00:17, 43.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 713M/1.46G [00:16<00:17, 43.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 724M/1.46G [00:16<00:17, 43.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 734M/1.46G [00:17<00:16, 43.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 744M/1.46G [00:17<00:16, 43.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 755M/1.46G [00:17<00:16, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 765M/1.46G [00:17<00:16, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 776M/1.46G [00:18<00:15, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 786M/1.46G [00:18<00:15, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 797M/1.46G [00:18<00:15, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 807M/1.46G [00:18<00:15, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 818M/1.46G [00:19<00:15, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 828M/1.46G [00:19<00:14, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 839M/1.46G [00:19<00:14, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 849M/1.46G [00:19<00:14, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 860M/1.46G [00:20<00:14, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 870M/1.46G [00:20<00:13, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 881M/1.46G [00:20<00:13, 43.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 891M/1.46G [00:20<00:13, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 902M/1.46G [00:21<00:13, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 912M/1.46G [00:21<00:12, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 923M/1.46G [00:21<00:12, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 933M/1.46G [00:21<00:12, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 944M/1.46G [00:22<00:12, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 954M/1.46G [00:22<00:11, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 965M/1.46G [00:22<00:11, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 975M/1.46G [00:22<00:11, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 986M/1.46G [00:23<00:11, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 996M/1.46G [00:23<00:10, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.01G/1.46G [00:23<00:10, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.02G/1.46G [00:23<00:10, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.03G/1.46G [00:24<00:10, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 1.04G/1.46G [00:24<00:09, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 1.05G/1.46G [00:24<00:09, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.06G/1.46G [00:24<00:09, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 1.07G/1.46G [00:25<00:09, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.08G/1.46G [00:25<00:08, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.09G/1.46G [00:25<00:08, 42.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.10G/1.46G [00:25<00:08, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 1.11G/1.46G [00:26<00:08, 42.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 1.12G/1.46G [00:26<00:07, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.13G/1.46G [00:26<00:07, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.14G/1.46G [00:26<00:07, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 1.15G/1.46G [00:26<00:07, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.16G/1.46G [00:27<00:06, 42.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 1.17G/1.46G [00:27<00:06, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 1.18G/1.46G [00:27<00:06, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 1.20G/1.46G [00:27<00:06, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 1.21G/1.46G [00:28<00:05, 42.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 1.22G/1.46G [00:28<00:05, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 1.23G/1.46G [00:28<00:05, 42.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.24G/1.46G [00:28<00:05, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.25G/1.46G [00:29<00:04, 42.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 1.26G/1.46G [00:29<00:04, 41.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 1.27G/1.46G [00:29<00:04, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.28G/1.46G [00:29<00:04, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.29G/1.46G [00:30<00:04, 42.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 1.30G/1.46G [00:30<00:03, 41.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 1.31G/1.46G [00:30<00:03, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.32G/1.46G [00:30<00:03, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 1.33G/1.46G [00:31<00:03, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 1.34G/1.46G [00:31<00:02, 41.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.35G/1.46G [00:31<00:02, 41.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 1.36G/1.46G [00:31<00:02, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 1.37G/1.46G [00:32<00:02, 42.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 1.38G/1.46G [00:32<00:01, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.39G/1.46G [00:32<00:01, 41.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.41G/1.46G [00:32<00:01, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 1.42G/1.46G [00:33<00:01, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.43G/1.46G [00:33<00:00, 41.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.44G/1.46G [00:33<00:00, 42.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  99% 1.45G/1.46G [00:33<00:00, 42.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.46G/1.46G [00:34<00:00, 42.6MB/s]\n",
            "Downloading shards: 100% 2/2 [02:32<00:00, 76.21s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:30<00:00, 15.35s/it]\n",
            "generation_config.json: 100% 189/189 [00:00<00:00, 1.42MB/s]\n",
            "tokenizer_config.json: 100% 54.5k/54.5k [00:00<00:00, 9.47MB/s]\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 9.19MB/s]\n",
            "special_tokens_map.json: 100% 296/296 [00:00<00:00, 2.03MB/s]\n",
            "Device set to use cuda:0\n",
            "modules.json: 100% 349/349 [00:00<00:00, 2.29MB/s]\n",
            "config_sentence_transformers.json: 100% 116/116 [00:00<00:00, 843kB/s]\n",
            "README.md: 100% 10.7k/10.7k [00:00<00:00, 39.6MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 379kB/s]\n",
            "config.json: 100% 612/612 [00:00<00:00, 4.15MB/s]\n",
            "model.safetensors: 100% 90.9M/90.9M [00:00<00:00, 225MB/s]\n",
            "tokenizer_config.json: 100% 350/350 [00:00<00:00, 2.88MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 49.8MB/s]\n",
            "tokenizer.json: 100% 466k/466k [00:00<00:00, 7.39MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 755kB/s]\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.62MB/s]\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "[{'role': 'system', 'content': 'You are a professional email assistant specializing in crafting compelling and structured business emails.'}, {'role': 'user', 'content': \"Generate a professional email with a compelling subject for GreenBuild Solutions team in a company in GreenBuild Solutions, a company in the Architecture & Construction industry.\\n\\nThe company has expressed a need for VR-based architectural visualization tools, and we offer the following relevant products:\\n\\n- VR Architect Pro: A high-end VR software for immersive architectural visualization.\\n- ImmersiBuild VR: An advanced VR platform for architects to visualize and modify structures in real-time.\\n- MediVR Sim: A VR-based medical training simulator for healthcare professionals.\\n\\nThe email should include:\\n- A relevant subject line\\n- A personalized greeting\\n- A concise, engaging introduction\\n- A brief mention of the relevant products\\n- A clear call to action for scheduling a discussion or demo\\n- A professional closing with the sender's name (Mahmoud Saad) and company (M.S)\\n\\nRespond with only the email subject and body.\"}, {'role': 'assistant', 'content': \"Subject: Unlock Immersive Architectural Visualization with GreenBuild Solutions\\n\\nDear GreenBuild Solutions Team,\\n\\nWe've been following your company's growth in the Architecture & Construction industry, and we're excited to explore how our cutting-edge VR-based architectural visualization tools can enhance your projects. Our team has developed innovative solutions that can revolutionize the way architects, designers, and builders collaborate and visualize structures.\\n\\nWe'd like to introduce you to our flagship products: VR Architect Pro, ImmersiBuild VR, and MediVR Sim. These tools offer unparalleled immersion and interactivity, allowing your team to refine designs, identify potential issues, and optimize building performance in a highly engaging and realistic environment.\\n\\nWe'd love to schedule a discussion or demo to show you how our solutions can benefit your business. Please let us know a convenient time and date, and we'll make sure to allocate the necessary resources.\\n\\nLooking forward to exploring the possibilities with you.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\"}]\n",
            "Unlock Immersive Architectural Visualization with GreenBuild Solutions\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "[{'role': 'system', 'content': 'You are a professional email assistant specializing in crafting compelling and structured business emails.'}, {'role': 'user', 'content': \"Generate a professional email with a compelling subject for MediTech Innovations team in a company in MediTech Innovations, a company in the Healthcare industry.\\n\\nThe company has expressed a need for VR-based medical training simulators, and we offer the following relevant products:\\n\\n- MediVR Sim: A VR-based medical training simulator for healthcare professionals.\\n- MediSim XR: A next-generation extended reality (XR) medical training simulator for surgery and\\n- EduVR Class: A VR-based virtual classroom solution for interactive online education.\\n\\nThe email should include:\\n- A relevant subject line\\n- A personalized greeting\\n- A concise, engaging introduction\\n- A brief mention of the relevant products\\n- A clear call to action for scheduling a discussion or demo\\n- A professional closing with the sender's name (Mahmoud Saad) and company (M.S)\\n\\nRespond with only the email subject and body.\"}, {'role': 'assistant', 'content': \"Subject: Revolutionizing Medical Training with Immersive VR Solutions\\n\\nDear MediTech Innovations Team,\\n\\nI am excited to introduce you to our cutting-edge VR-based medical training simulators designed to elevate the quality of healthcare education and training within your organization. At M.S, we specialize in developing innovative solutions that bridge the gap between theoretical knowledge and practical skills.\\n\\nOur comprehensive portfolio includes MediVR Sim, a VR-based medical training simulator for healthcare professionals, and MediSim XR, a next-generation extended reality (XR) medical training simulator for surgery. These immersive solutions allow your team to engage in realistic, interactive training sessions that foster a deeper understanding of medical procedures and enhance overall performance.\\n\\nWe believe that our VR-based medical training simulators can significantly enhance your organization's training programs. I would be delighted to schedule a discussion or demo to explore how our solutions can address your specific needs and goals.\\n\\nPlease let me know if you would like to schedule a call at your convenience. I look forward to the opportunity to discuss how we can support MediTech Innovations.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\"}]\n",
            "Revolutionizing Medical Training with Immersive VR Solutions\n",
            "Sent Emails:\n",
            "(1, 'GreenBuild Solutions', 'mahmoud.saad.mahmoud.11@gmail.com', 'Unlock Immersive Architectural Visualization with GreenBuild Solutions', \"Dear GreenBuild Solutions Team,\\n\\nWe've been following your company's growth in the Architecture & Construction industry, and we're excited to explore how our cutting-edge VR-based architectural visualization tools can enhance your projects. Our team has developed innovative solutions that can revolutionize the way architects, designers, and builders collaborate and visualize structures.\\n\\nWe'd like to introduce you to our flagship products: VR Architect Pro, ImmersiBuild VR, and MediVR Sim. These tools offer unparalleled immersion and interactivity, allowing your team to refine designs, identify potential issues, and optimize building performance in a highly engaging and realistic environment.\\n\\nWe'd love to schedule a discussion or demo to show you how our solutions can benefit your business. Please let us know a convenient time and date, and we'll make sure to allocate the necessary resources.\\n\\nLooking forward to exploring the possibilities with you.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-10 12:27:56')\n",
            "(2, 'MediTech Innovations', 'mahm0udsa3d404@gmail.com', 'Revolutionizing Medical Training with Immersive VR Solutions', \"Dear MediTech Innovations Team,\\n\\nI am excited to introduce you to our cutting-edge VR-based medical training simulators designed to elevate the quality of healthcare education and training within your organization. At M.S, we specialize in developing innovative solutions that bridge the gap between theoretical knowledge and practical skills.\\n\\nOur comprehensive portfolio includes MediVR Sim, a VR-based medical training simulator for healthcare professionals, and MediSim XR, a next-generation extended reality (XR) medical training simulator for surgery. These immersive solutions allow your team to engage in realistic, interactive training sessions that foster a deeper understanding of medical procedures and enhance overall performance.\\n\\nWe believe that our VR-based medical training simulators can significantly enhance your organization's training programs. I would be delighted to schedule a discussion or demo to explore how our solutions can address your specific needs and goals.\\n\\nPlease let me know if you would like to schedule a call at your convenience. I look forward to the opportunity to discuss how we can support MediTech Innovations.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\", 'sent', '2025-02-10 12:28:08')\n",
            "\n",
            "Received Emails:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN8siD4sN5GP",
        "outputId": "d8034449-f8fe-4449-e0cf-60fe6c41f5ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No new emails found.\n",
            "\n",
            "New Email from mahmoud.saad.mahmoud.11@gmail.com: Re: VR-Based Architectural Visualization Tools\n",
            "Passing 1 emails to /content/response.py...\n",
            "2025-02-10 12:29:35.167999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739190575.210388    2335 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739190575.223304    2335 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-10 12:29:35.281637: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Hi\n",
            "['mahmoud.saad.mahmoud.11@gmail.com']\n",
            "config.json: 100% 1.15k/1.15k [00:00<00:00, 8.54MB/s]\n",
            "model.safetensors: 100% 1.63G/1.63G [00:07<00:00, 231MB/s]\n",
            "tokenizer_config.json: 100% 26.0/26.0 [00:00<00:00, 151kB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 13.0MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 67.3MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 20.1MB/s]\n",
            "Device set to use cuda:0\n",
            "Loading checkpoint shards: 100% 2/2 [00:29<00:00, 14.86s/it]\n",
            "Device set to use cuda:0\n",
            "Processing email from mahmoud.saad.mahmoud.11@gmail.com...\n",
            "Category: Need more details\n",
            "11111\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "No new emails found.\n",
            "[{'role': 'system', 'content': 'You are a professional email assistant who writes structured responses.'}, {'role': 'user', 'content': \"Given the conversation history for GreenBuild Solutions in the Re: VR-Based Architectural Visualization Tools industry, generate a well-structured response.\\n\\nConversation:\\nsent: Dear GreenBuild Solutions Team,\\n\\nWe've been following your company's growth in the Architecture & Construction industry, and we're excited to explore how our cutting-edge VR-based architectural visualization tools can enhance your projects. Our team has developed innovative solutions that can revolutionize the way architects, designers, and builders collaborate and visualize structures.\\n\\nWe'd like to introduce you to our flagship products: VR Architect Pro, ImmersiBuild VR, and MediVR Sim. These tools offer unparalleled immersion and interactivity, allowing your team to refine designs, identify potential issues, and optimize building performance in a highly engaging and realistic environment.\\n\\nWe'd love to schedule a discussion or demo to show you how our solutions can benefit your business. Please let us know a convenient time and date, and we'll make sure to allocate the necessary resources.\\n\\nLooking forward to exploring the possibilities with you.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\\nreceived: Dear Mahmoud Saad,\\r\\n\\r\\nThank you for reaching out and for your interest in collaborating with\\r\\nGreenBuild Solutions. Your VR-based architectural visualization tools sound\\r\\npromising, and we'd love to explore how they might align with our current\\r\\nworkflows.\\r\\n\\r\\nCould you provide additional details on the following?\\r\\n\\r\\n   - The level of detail and interactivity your visualization tools offer\\r\\n   for architectural designs.\\r\\n   - How real-time collaboration functions within your solutions.\\r\\n   - Compatibility with existing architectural software such as AutoCAD,\\r\\n   Revit, or BIM platforms.\\r\\n   - Pricing structure and licensing options.\\r\\n\\r\\nWeâ€™d appreciate more insights on these points before scheduling a call or\\r\\ndemo. Looking forward to your response.\\r\\n\\r\\nBest regards,\\r\\nGreenBuild Solutions Team\\r\\n\\n\\nProduct Details:\\n- {'Product Name': 'VR Architect Pro', 'Industry': 'Architecture & Construction', 'Description': 'A high-end VR software for immersive architectural visualization.', 'Specifications': 'Supports BIM integration, cloud-based storage, and multi-user design collaboration.', 'Case Study': 'Used in SmartCity development, reducing project planning time by 25%.', 'Compliance': 'LEED-certified visualization tools.'}\"}, {'role': 'assistant', 'content': \"Subject: Re: VR-Based Architectural Visualization Tools\\n\\nDear GreenBuild Solutions Team,\\n\\nThank you for your prompt response and for expressing interest in exploring how our VR-based architectural visualization tools can benefit your business. We're excited to learn more about your current workflows and how our solutions can align with them.\\n\\nWe'd be happy to provide the additional details you requested:\\n\\n1. **Level of detail and interactivity**: Our flagship products, VR Architect Pro, ImmersiBuild VR, and MediVR Sim, offer an unparalleled level of immersion and interactivity in architectural visualization. Users can refine designs, identify potential issues, and optimize building performance in a highly engaging and realistic environment. Our tools provide real-time rendering, 3D modeling, and physics-based simulations, allowing for a more accurate and immersive visualization experience.\\n\\n2. **Real-time collaboration**: Our solutions enable seamless real-time collaboration among architects, designers, and builders. With our cloud-based storage and multi-user design collaboration features, teams can work together on projects from anywhere, at any time. We've seen significant improvements in project efficiency and productivity with our real-time collaboration capabilities.\\n\\n3. **Compatibility with existing architectural software**: Our tools are compatible with popular architectural software such as AutoCAD, Revit, and BIM platforms. We've developed robust integrations to ensure a smooth workflow, allowing users to import and export data seamlessly.\\n\\n4. **Pricing structure and licensing options**: We offer a flexible pricing structure to accommodate different business needs. Our packages include:\\n\\n   - **Starter**: $X per month (billed annually) for a single user, ideal for small projects or individual users.\\n   - **Pro**: $Y per month (billed annually) for up to 5 users, suitable for medium-sized projects or teams.\\n   - **Enterprise**: Custom pricing for large-scale projects or organizations with multiple teams.\\n\\nWe'd be happy to provide more information and discuss the specifics of our pricing structure and licensing options.\\n\\nBefore scheduling a call or demo, we'd like to propose a few options:\\n\\n- **Free Trial**: We can provide a 30-day free trial of our flagship products, allowing you to experience the benefits firsthand.\\n- **Demo**: We can schedule a 30-minute demo to showcase our tools and answer any questions you may have.\\n- **Customized Solution**: We can work with your team to develop a customized solution tailored to your specific needs and workflows.\\n\\nPlease let us know which option you prefer, or if you have any other suggestions.\\n\\nLooking forward to hearing back from\"}]\n",
            "22222222\n",
            "Sent response to mahmoud.saad.mahmoud.11@gmail.com for GreenBuild Solutions\n",
            "âœ… Emails categorized, responses sent, and database updated.\n",
            "waiting\n",
            "\n",
            "New Email from mahm0udsa3d404@gmail.com: Re: VR-Based Medical Training Solutions Inquiryâ€â€â€â€â€â€â€â€â€â€\n",
            "Queued 1 emails.\n",
            "\n",
            "New Email from mahmoud.saad.mahmoud.11@gmail.com: Quick Follow-Up on VR Tools\n",
            "Queued 1 emails.\n",
            "No new emails found.\n",
            "Queued 0 emails.\n",
            "finished\n",
            "No new emails found.\n",
            "Processing 2 queued emails...\n",
            "Passing 2 emails to /content/response.py...\n",
            "2025-02-10 12:34:44.023306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739190884.050034    3667 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739190884.059300    3667 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-10 12:34:44.111318: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Hi\n",
            "['mahm0udsa3d404@gmail.com', 'mahmoud.saad.mahmoud.11@gmail.com']\n",
            "Device set to use cuda:0\n",
            "Loading checkpoint shards: 100% 2/2 [00:27<00:00, 13.91s/it]\n",
            "Device set to use cuda:0\n",
            "Processing email from mahm0udsa3d404@gmail.com...\n",
            "Category: Want to make a meeting\n",
            "Processing email from mahmoud.saad.mahmoud.11@gmail.com...\n",
            "Category: Need more details\n",
            "11111\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "No new emails found.\n",
            "[{'role': 'system', 'content': 'You are a professional email assistant who writes structured responses.'}, {'role': 'user', 'content': \"Given the conversation history for GreenBuild Solutions in the Quick Follow-Up on VR Tools industry, generate a well-structured response.\\n\\nConversation:\\nsent: Dear GreenBuild Solutions Team,\\n\\nWe've been following your company's growth in the Architecture & Construction industry, and we're excited to explore how our cutting-edge VR-based architectural visualization tools can enhance your projects. Our team has developed innovative solutions that can revolutionize the way architects, designers, and builders collaborate and visualize structures.\\n\\nWe'd like to introduce you to our flagship products: VR Architect Pro, ImmersiBuild VR, and MediVR Sim. These tools offer unparalleled immersion and interactivity, allowing your team to refine designs, identify potential issues, and optimize building performance in a highly engaging and realistic environment.\\n\\nWe'd love to schedule a discussion or demo to show you how our solutions can benefit your business. Please let us know a convenient time and date, and we'll make sure to allocate the necessary resources.\\n\\nLooking forward to exploring the possibilities with you.\\n\\nBest regards,\\nMahmoud Saad\\nM.S\\nreceived: Dear Mahmoud Saad,\\r\\n\\r\\nThank you for reaching out and for your interest in collaborating with\\r\\nGreenBuild Solutions. Your VR-based architectural visualization tools sound\\r\\npromising, and we'd love to explore how they might align with our current\\r\\nworkflows.\\r\\n\\r\\nCould you provide additional details on the following?\\r\\n\\r\\n   - The level of detail and interactivity your visualization tools offer\\r\\n   for architectural designs.\\r\\n   - How real-time collaboration functions within your solutions.\\r\\n   - Compatibility with existing architectural software such as AutoCAD,\\r\\n   Revit, or BIM platforms.\\r\\n   - Pricing structure and licensing options.\\r\\n\\r\\nWeâ€™d appreciate more insights on these points before scheduling a call or\\r\\ndemo. Looking forward to your response.\\r\\n\\r\\nBest regards,\\r\\nGreenBuild Solutions Team\\r\\n\\nsent: Dear GreenBuild Solutions Team,\\n\\nThank you for your prompt response and for expressing interest in exploring how our VR-based architectural visualization tools can benefit your business. We're excited to learn more about your current workflows and how our solutions can align with them.\\n\\nWe'd be happy to provide the additional details you requested:\\n\\n1. **Level of detail and interactivity**: Our flagship products, VR Architect Pro, ImmersiBuild VR, and MediVR Sim, offer an unparalleled level of immersion and interactivity in architectural visualization. Users can refine designs, identify potential issues, and optimize building performance in a highly engaging and realistic environment. Our tools provide real-time rendering, 3D modeling, and physics-based simulations, allowing for a more accurate and immersive visualization experience.\\n\\n2. **Real-time collaboration**: Our solutions enable seamless real-time collaboration among architects, designers, and builders. With our cloud-based storage and multi-user design collaboration features, teams can work together on projects from anywhere, at any time. We've seen significant improvements in project efficiency and productivity with our real-time collaboration capabilities.\\n\\n3. **Compatibility with existing architectural software**: Our tools are compatible with popular architectural software such as AutoCAD, Revit, and BIM platforms. We've developed robust integrations to ensure a smooth workflow, allowing users to import and export data seamlessly.\\n\\n4. **Pricing structure and licensing options**: We offer a flexible pricing structure to accommodate different business needs. Our packages include:\\n\\n   - **Starter**: $X per month (billed annually) for a single user, ideal for small projects or individual users.\\n   - **Pro**: $Y per month (billed annually) for up to 5 users, suitable for medium-sized projects or teams.\\n   - **Enterprise**: Custom pricing for large-scale projects or organizations with multiple teams.\\n\\nWe'd be happy to provide more information and discuss the specifics of our pricing structure and licensing options.\\n\\nBefore scheduling a call or demo, we'd like to propose a few options:\\n\\n- **Free Trial**: We can provide a 30-day free trial of our flagship products, allowing you to experience the benefits firsthand.\\n- **Demo**: We can schedule a 30-minute demo to showcase our tools and answer any questions you may have.\\n- **Customized Solution**: We can work with your team to develop a customized solution tailored to your specific needs and workflows.\\n\\nPlease let us know which option you prefer, or if you have any other suggestions.\\n\\nLooking forward to hearing back from\\nreceived: Dear Mahmoud Saad,\\r\\n\\r\\nThank you for your detailed response. I just had a few quick questions:\\r\\n\\r\\n   1. Does VR Architect Pro work on computers?\\r\\n   2. Can users wear VR headsets while using your tools?\\r\\n   3. Is the software available in color, or just black and white?\\r\\n   4. Do the tools require electricity to function?\\r\\n   5. Is there a specific button to start the software, or does it open\\r\\n   automatically?\\r\\n\\r\\nI appreciate your time and look forward to your insights.\\r\\n\\r\\nBest regards,\\r\\nGreenBuild Solutions\\r\\n\\n\\nProduct Details:\\n- {'Product Name': 'VR Architect Pro', 'Industry': 'Architecture & Construction', 'Description': 'A high-end VR software for immersive architectural visualization.', 'Specifications': 'Supports BIM integration, cloud-based storage, and multi-user design collaboration.', 'Case Study': 'Used in SmartCity development, reducing project planning time by 25%.', 'Compliance': 'LEED-certified visualization tools.'}\"}, {'role': 'assistant', 'content': \"Subject: Re: Exploring the Possibilities of VR-Based Architectural Visualization Tools\\n\\nDear GreenBuild Solutions Team,\\n\\nThank you for your prompt and detailed response. We appreciate the additional information you provided regarding your VR-based architectural visualization tools. Your solutions seem to align well with our current workflows, and we're excited to explore the possibilities of collaborating with your team.\\n\\nTo further clarify your responses, we'd like to ask a few more questions:\\n\\n1. **VR Architect Pro on computers**: Yes, VR Architect Pro is compatible with computers, and we can provide a detailed list of system requirements for optimal performance.\\n2. **VR headsets**: Our tools are designed to work seamlessly with VR headsets, allowing users to fully immerse themselves in the visualization experience. However, we also offer a non-VR mode for those who prefer to use our tools on a traditional screen.\\n3. **Color and black and white**: Our software supports a wide range of color palettes, including custom colors and gradients. We also offer a black and white mode for those who prefer a more traditional visualization experience.\\n4. **Electricity requirements**: Our tools do not require electricity to function, as they are cloud-based and can be accessed from anywhere with an internet connection.\\n5. **Software start-up**: Our software opens automatically when a user logs in, and there is no specific button to start the software. We also offer a tutorial and user guide to help users get started with our tools.\\n\\nRegarding your proposed options, we're interested in exploring the **Free Trial** option, which would allow us to experience the benefits of your flagship products firsthand. We'd also appreciate a **Demo** to showcase your tools and answer any questions we may have.\\n\\nBefore we proceed, we'd like to request a few more details:\\n\\n* **Implementation timeline**: Can you provide an estimated timeline for implementing your solutions in our organization?\\n* **Training and support**: What kind of training and support can we expect from your team during the implementation process?\\n* **Integration with existing workflows**: How will your solutions integrate with our existing workflows, and what kind of customization can we expect?\\n\\nPlease let us know if these questions are acceptable, and we'll proceed with the next steps.\\n\\nThank you for your time and assistance.\\n\\nBest regards,\\nGreenBuild Solutions\"}]\n",
            "22222222\n",
            "Sent response to mahmoud.saad.mahmoud.11@gmail.com for GreenBuild Solutions\n",
            "âœ… Emails categorized, responses sent, and database updated.\n",
            "waiting\n",
            "No new emails found.\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/event_driven_emails.py\", line 201, in <module>\n",
            "  File \"/content/response.py\", line 201, in <module>\n",
            "    time.sleep(60)\n",
            "KeyboardInterrupt\n",
            "    time.sleep(random.randint(180, 200))\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python event_driven_emails.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}